{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, BNode, XSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichiers existants\n",
    "addr_ont_file_name = \"address_ont.ttl\"\n",
    "ev_ont_file_name = \"events_ont.ttl\"\n",
    "ont_file_name = \"merge_addr_ont.ttl\" # Fusion des deux fichiers précédents\n",
    "ruleset_file_name = \"rules_sameAs.pie\"\n",
    "\n",
    "# Fichiers créés durant le processus\n",
    "export_file_name = \"addresses-temp.ttl\"\n",
    "out_file_name = \"addresses.ttl\"\n",
    "local_config_file_name = \"config_repo.ttl\"\n",
    "\n",
    "# Dossiers existants\n",
    "data_folder_name = \"data\"\n",
    "mapping_folder_name = \"mappings\"\n",
    "\n",
    "# Dossiers créés durant le traitement\n",
    "tmp_folder_name = \"tmp_files\"\n",
    "\n",
    "project_name = \"addresses_from_factoids_same_as\"\n",
    "ontology_named_graph_name = \"ontology\"\n",
    "\n",
    "graphdb_url = \"http://localhost:7200\"\n",
    "ontorefine_url = \"http://localhost:7333\"\n",
    "local_uri = \"http://rdf.geohistoricaldata.org/id/address/\"\n",
    "\n",
    "# Commande pour lancer `Ontorefine`, dépend de l'OS et d'où il se situe\n",
    "# ontorefine_cmd = \"ontorefine-cli\" # Nom sans chemin\n",
    "ontorefine_cmd = \"/opt/ontotext-refine/lib/app/bin/ontorefine-cli\" #Ubuntu\n",
    "# ontorefine_cmd = \"/Applications/Ontotext\\ Refine.app/Contents/app/bin/ontorefine-cli\" #MacOS\n",
    "\n",
    "addr_graph_name = \"addresses_from_factoids\"\n",
    "\n",
    "py_code_folder_path = \"../code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des variables globales\n",
    "\n",
    "* Obtention des chemins absolus des fichiers à partir des chemins relatifs donnés dans la section précédente\n",
    "* Création d'un dossier temporaire s'il n'existe pas encore pour stocker des fichiers à vocation d'être supprimés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_folder = os.path.abspath(tmp_folder_name)\n",
    "mapping_folder = os.path.abspath(mapping_folder_name)\n",
    "data_folder = os.path.abspath(data_folder_name)\n",
    "\n",
    "python_code_folder = os.path.abspath(py_code_folder_path)\n",
    "\n",
    "local_config_file = os.path.join(tmp_folder, local_config_file_name)\n",
    "addr_ont_file = os.path.abspath(addr_ont_file_name)\n",
    "ev_ont_file = os.path.abspath(ev_ont_file_name)\n",
    "ont_file = os.path.abspath(ont_file_name)\n",
    "ruleset_file = os.path.abspath(ruleset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des modules situés dans le dossier `code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appel du dossier `code` comprend les codes python\n",
    "sys.path.insert(1, python_code_folder)\n",
    "\n",
    "import filemanagement as fm\n",
    "import wikidata as wd\n",
    "import ontorefine as otr\n",
    "import graphdb as gd\n",
    "import graphrdf as gr\n",
    "import strprocessing as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de dossiers s'ils n'existent pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.create_folder_if_not_exists(tmp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion du répertoire local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du répertoire local dans GraphDB\n",
    "Pour que la création marche, il faut que GraphDB soit lancé et donc que l'URI donné par `graphdb_url` fonctionne. Si le répertoire existe déjà, rien n'est fait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.remove_repository(graphdb_url, project_name)\n",
    "gd.create_config_local_repository_file(local_config_file, project_name, ruleset_file=ruleset_file)\n",
    "# gd.create_config_local_repository_file(local_config_file, project_name)\n",
    "gd.create_repository_from_config_file(graphdb_url, local_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vidage du répertoire local\n",
    "Le répertoire dont l'id est `project_name` pour y stocker les données récupérées, cela est utile si le répertoire existait déjà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.clear_repository(graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de l'ontologie\n",
    "# gd.import_ttl_file_in_graphdb(graphdb_url, project_name, addr_ont_file)\n",
    "# gd.import_ttl_file_in_graphdb(graphdb_url, project_name, ev_ont_file)\n",
    "gd.import_ttl_file_in_graphdb(graphdb_url, project_name, ont_file, ontology_named_graph_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition de variables liées aux sources et aux faits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphe de faits, accumulation des données des sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du graphe nommé\n",
    "facts_graph_name = \"facts\"\n",
    "facts_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, facts_graph_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voies de Paris via Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `wdpt` pour \"wikidata paris thoroughfares\"\n",
    "\n",
    "# Fichier CSV pour stocker le résultat de la requête de la sélection\n",
    "wdpt_csv_file_name = \"wd_paris_thoroughfares.csv\"\n",
    "wdpt_csv_file = os.path.join(tmp_folder, wdpt_csv_file_name)\n",
    "\n",
    "# Fichier de mapping pour transformer le fichier CSV en fichier TTL\n",
    "wdpt_mapping_file_name = \"mapping_voies_wikidata.json\"\n",
    "wdpt_mapping_file = os.path.join(mapping_folder, wdpt_mapping_file_name)\n",
    "\n",
    "# Fichier TTL pour structurer les connaissances des voies de Paris\n",
    "wdpt_kg_file_name = \"wd_paris_thoroughfares.ttl\"\n",
    "wdpt_kg_file = os.path.join(tmp_folder, wdpt_kg_file_name)\n",
    "\n",
    "# Définition des graphes nommés\n",
    "wdpt_graph_name = \"wikidata\"\n",
    "wdpt_ids_graph_name = \"wikidata_ids\"\n",
    "wdpt_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, wdpt_graph_name))\n",
    "wdpt_ids_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, wdpt_ids_graph_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomenclature des voies de la ville de Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données de la ville de Paris sont composées de deux jeux :\n",
    "* [dénominations des emprises des voies actuelles](https://opendata.paris.fr/explore/dataset/denominations-emprises-voies-actuelles)\n",
    "* [dénominations caduques des voies](https://opendata.paris.fr/explore/dataset/denominations-des-voies-caduques)\n",
    "\n",
    "Les voies actuelles ont une emprise géométrique contrairement aux anciennes voies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `vpt` pour \"ville paris thoroughfares\"\n",
    "\n",
    "# Fichier CSV pour stocker le résultat de la requête de la sélection\n",
    "vpta_csv_file_name = \"denominations-emprises-voies-actuelles.csv\"\n",
    "vpta_csv_file = os.path.join(data_folder, vpta_csv_file_name)\n",
    "vptc_csv_file_name = \"denominations-des-voies-caduques.csv\"\n",
    "vptc_csv_file = os.path.join(data_folder, vptc_csv_file_name)\n",
    "\n",
    "# Fichier de mapping pour transformer le fichier CSV en fichier TTL\n",
    "vpta_mapping_file_name = \"mapping_voies_paris_actuelles.json\"\n",
    "vpta_mapping_file = os.path.join(mapping_folder, vpta_mapping_file_name)\n",
    "vptc_mapping_file_name = \"mapping_voies_paris_caduques.json\"\n",
    "vptc_mapping_file = os.path.join(mapping_folder, vptc_mapping_file_name)\n",
    "\n",
    "# Fichier TTL pour structurer les connaissances des voies de Paris\n",
    "vpta_kg_file_name = \"voies_paris_actuelles.ttl\"\n",
    "vpta_kg_file = os.path.join(tmp_folder, vpta_kg_file_name)\n",
    "vptc_kg_file_name = \"voies_paris_caduques.ttl\"\n",
    "vptc_kg_file = os.path.join(tmp_folder, vptc_kg_file_name)\n",
    "\n",
    "# Définition des graphes nommés\n",
    "vpt_graph_name = \"ville_de_paris\"\n",
    "vpt_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, vpt_graph_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Adresse Nationale (BAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données de la [Base Adresse Nationale (BAN)](https://adresse.data.gouv.fr/base-adresse-nationale), accessible [ici](https://adresse.data.gouv.fr/data/ban/adresses/latest/csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `bpa` pour \"BAN paris addresses\"\n",
    "\n",
    "# Fichier CSV pour stocker le résultat de la requête de la sélection\n",
    "bpa_csv_file_name = \"ban_adresses.csv\"\n",
    "bpa_csv_file = os.path.join(data_folder, bpa_csv_file_name)\n",
    "\n",
    "# Fichier de mapping pour transformer le fichier CSV en fichier TTL\n",
    "bpa_mapping_file_name = \"mapping_ban_adresses.json\"\n",
    "bpa_mapping_file = os.path.join(mapping_folder, bpa_mapping_file_name)\n",
    "\n",
    "# Fichier TTL pour structurer les connaissances des voies de Paris\n",
    "bpa_kg_file_name = \"ban_adresses.ttl\"\n",
    "bpa_kg_file = os.path.join(tmp_folder, bpa_kg_file_name)\n",
    "\n",
    "# Définition des graphes nommés\n",
    "bpa_graph_name = \"ban\"\n",
    "bpa_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, bpa_graph_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions pour des traitements de construction des graphes de factoïdes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de labels normalisés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Étant donné les variations de labels qui sont similaires, la normalisation consiste ici à :\n",
    "    * la mise en minuscule des caractères\n",
    "    * suppression des signes diacritiques (accents, cédille...)\n",
    "    * suppression de termes \"inutiles\" : déterminants, prépositions...\n",
    "* Ces labels normalisés sont liés aux repères via `skos:hiddenLabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normalized_label_for_landmarks(graphdb_url, project_name, source_graph_uri:URIRef):\n",
    "    \"\"\"\n",
    "    Ajout de labels normalisés pour les repères via `skos:hiddenLabel` dans le graphe nommé temporaire `tmp_graph_uri`\n",
    "    \"\"\"\n",
    "\n",
    "    label_var = \"?label\"\n",
    "    norm_label_var = \"?normLabel\"\n",
    "    norm_label_function = sp.get_lower_simplified_french_street_name_function(label_var)\n",
    "\n",
    "    prefixes = \"\"\"\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#>\n",
    "    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX ltype: <http://rdf.geohistoricaldata.org/id/codes/address/landmarkType/>\n",
    "    PREFIX atype: <http://rdf.geohistoricaldata.org/id/codes/address/attributeType/>\n",
    "    \"\"\"\n",
    "\n",
    "    query = prefixes + f\"\"\"\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?landmark skos:hiddenLabel {norm_label_var}.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        GRAPH ?g {{\n",
    "            ?landmark a addr:Landmark; addr:hasAttribute [a addr:Attribute; addr:isAttributeType atype:NameAttribute; addr:version [a addr:AttributeVersion; addr:versionValue {label_var}]].\n",
    "            BIND({norm_label_function} AS {norm_label_var})\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des instants temporels sans timeStamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe des resources de classe `addr:TimeInstant` qui ont un calendrier et une granularité dans avoir de time stamp. Il faut supprimer ces ressources qui n'ont aucune utilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_time_instant_without_timestamp(graphdb_url, project_name, source_graph_uri:URIRef):\n",
    "    query = f\"\"\"\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#> \n",
    "    DELETE {{\n",
    "        ?timeInstant ?p ?o.\n",
    "        ?s ?p ?timeInstant.\n",
    "    }}WHERE {{\n",
    "        GRAPH {source_graph_uri.n3()} {{\n",
    "            ?timeInstant a addr:TimeInstant.\n",
    "            MINUS {{?timeInstant addr:timeStamp ?timeStamp}}\n",
    "            {{?timeInstant ?p ?o}}UNION{{?s ?p ?timeInstant}}\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'un lien entre les repères et les sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un factoïde est la représentation d'une information, d'un fait dans une source. Ici, on crée des repères qui ont une identité définie par la source. Ces derniers doivent avoir un lien avec la source afin d'attester la provenance de son existence.\n",
    "\n",
    "Pour cela, on sélectionne l'ensemble des repères (`?landmark`) situés dans le graphe nommé défini par `source_graph_uri` afin de créer le triplet `<?landmark rico:isOrWasDescribedBy ?sourceUri>` où `?sourceUri` est l'URI décrivant la source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_source_resources_links(graphdb_url, project_name, source_resource_uri:URIRef, source_graph_uri:URIRef):\n",
    "    query = f\"\"\"\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#> \n",
    "    PREFIX facts: <http://rdf.geohistoricaldata.org/id/address/facts/>\n",
    "    PREFIX rico: <https://www.ica.org/standards/RiC/ontology#>\n",
    "\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?elem rico:isOrWasDescribedBy {source_resource_uri.n3()}.\n",
    "        }}\n",
    "    }}WHERE {{\n",
    "        {{?type rdfs:subClassOf* addr:Landmark}} UNION\n",
    "        {{?type rdfs:subClassOf* addr:LandmarkRelation}} UNION\n",
    "        {{?type rdfs:subClassOf* addr:AttributeVersion}} UNION\n",
    "        {{?type rdfs:subClassOf* addr:Address}} UNION\n",
    "        {{?type rdfs:subClassOf* addr:Change}} UNION\n",
    "        {{?type rdfs:subClassOf* addr:Event}} UNION\n",
    "        {{?type rdfs:subClassOf* addr:TemporalEntity}}\n",
    "\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        GRAPH ?g {{\n",
    "            ?elem a ?type.\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion du fichier brut vers le graphe dans GraphDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir un fichier brut (un fichier tabulaire comme un CSV), la fonction le convertit en graphe de connaissances dans un fichier `ttl` (ici `kg_file`). La manière de convertir le fichier est défini par le fichier `ontorefine_mapping_file`, la conversion se fait par Ontotext Refine. Par la suite, le fichier `ttl` est importé dans le répertoire dont le nom est `project_name`, plus précisément dans le graphe nommé `graph_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_raw_to_data_to_graphdb(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, graph_name, csv_file, ontorefine_mapping_file, kg_file):\n",
    "    # Si ça ne marche pas ici, c'est sûrement qu'Ontotext Refine n'est pas lancé\n",
    "    otr.get_export_file_from_ontorefine(csv_file, ontorefine_mapping_file, kg_file, ontorefine_cmd, ontorefine_url, project_name)\n",
    "\n",
    "    # Importer le fichier `kg_file` qui a été créé lors de la ligne précédente dans le répertoire `project_name`, dans le graphe nommé `graph_name` \n",
    "    gd.import_ttl_file_in_graphdb(graphdb_url, project_name, kg_file, graph_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction des factoïdes pour chaque source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomenclature des voies de la ville de Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des données liées à la source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_ville_paris(graphdb_url, project_name, source_resource_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    query = f\"\"\"\n",
    "        PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#> \n",
    "        PREFIX facts: <http://rdf.geohistoricaldata.org/id/address/facts/>\n",
    "        PREFIX rico: <https://www.ica.org/standards/RiC/ontology#>\n",
    "\n",
    "        INSERT DATA {{\n",
    "            GRAPH {facts_graph_uri.n3()} {{\n",
    "                {source_resource_uri.n3()} a rico:Record;\n",
    "                    rdfs:label \"dénomination des voies de Paris (actuelles et caduques)\"@fr;\n",
    "                    rico:hasPublisher facts:DirTopoDocFoncVP .\n",
    "                facts:DirTopoDocFoncVP a rico:CorporateBody;\n",
    "                    rdfs:label \"Département de la Topographie et de la Documentation Foncière de la Ville de Paris\"@fr.    \n",
    "            }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'un processus de création des données de la Ville de Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_factoid_process_ville_paris(graphdb_url, project_name,\n",
    "                                       ontorefine_url, ontorefine_cmd,\n",
    "                                        vpt_graph_name, facts_graph_name, \n",
    "                                        vpta_csv_file, vptc_csv_file,\n",
    "                                        vpta_mapping_file, vptc_mapping_file,\n",
    "                                        vpta_kg_file, vptc_kg_file):\n",
    "    \"\"\"\n",
    "    Fonction pour faire l'ensemble des processus relatifs à la création des factoïdes pour les données de la dénomination des voies de la ville de Paris\n",
    "    \"\"\"\n",
    "\n",
    "    # Récupération des URI des graphes nommés\n",
    "    vpt_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, vpt_graph_name))\n",
    "    facts_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, facts_graph_name))\n",
    "\n",
    "    # A partir des fichiers csv décrivant les voies de la ville de Paris, convertir en un graphe de connaissance selon le mapping défini\n",
    "    # Puis import du graphe dans le répertoire dont le nom est `project_name` et dans le graphe nommé donné par `graph_name`\n",
    "    from_raw_to_data_to_graphdb(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, vpt_graph_name, vpta_csv_file, vpta_mapping_file, vpta_kg_file)\n",
    "    from_raw_to_data_to_graphdb(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, vpt_graph_name, vptc_csv_file, vptc_mapping_file, vptc_kg_file)\n",
    "\n",
    "    # Suppression des instants qui n'ont aucun timeStamp (instants sans date)\n",
    "    remove_time_instant_without_timestamp(graphdb_url, project_name, vpt_graph_uri)\n",
    "    \n",
    "    # L'URI ci-dessous définit la source liée à la ville de Paris\n",
    "    vdp_source_uri = URIRef(\"http://rdf.geohistoricaldata.org/id/address/facts/Source_VDP\")\n",
    "    create_source_ville_paris(graphdb_url, project_name, vdp_source_uri, facts_graph_uri)\n",
    "\n",
    "    # Ajout de labels normalisés\n",
    "    add_normalized_label_for_landmarks(graphdb_url, project_name, vpt_graph_uri)\n",
    "\n",
    "    # Ajout de liens entre les ressources de type repère et la source\n",
    "    add_source_resources_links(graphdb_url, project_name, vdp_source_uri, vpt_graph_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Adresse Nationale (BAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des données liées à la source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_ban(graphdb_url, project_name, source_resource_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    query = f\"\"\"\n",
    "        PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#> \n",
    "        PREFIX facts: <http://rdf.geohistoricaldata.org/id/address/facts/>\n",
    "        PREFIX rico: <https://www.ica.org/standards/RiC/ontology#>\n",
    "\n",
    "        INSERT DATA {{\n",
    "            GRAPH {facts_graph_uri.n3()} {{\n",
    "                {source_resource_uri.n3()} a rico:Record;\n",
    "                    rdfs:label \"Base Nationale Adresse\"@fr;\n",
    "                    rico:hasPublisher facts:DINUM_ANCT_IGN .\n",
    "                facts:IGN_DINUM_ANCT a rico:CorporateBody;\n",
    "                    rdfs:label \"DINUM / ANCT / IGN\"@fr.\n",
    "            }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage du graphe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détection de repères décrits via plusieurs ressources et création d'une unique ressource pour chaque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détection des communes et arrondissements dupliqués et création d'une source centrale (?newLandmark) selon le code INSEE.\n",
    "def clean_ban_graph(graphdb_url, project_name, source_graph_uri):\n",
    "    prefixes = \"\"\"\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX geofla: <http://data.ign.fr/def/geofla#>\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#>\n",
    "    PREFIX ltype: <http://rdf.geohistoricaldata.org/id/codes/address/landmarkType/>\n",
    "    PREFIX ban: <http://rdf.geohistoricaldata.org/id/address/sources/ban/>\n",
    "    \"\"\"\n",
    "\n",
    "    label_var = \"?label\"\n",
    "    norm_label_var = \"?normLabel\"\n",
    "    norm_label_function = sp.get_lower_simplified_french_street_name_function(label_var)\n",
    "\n",
    "    query1 = prefixes + f\"\"\"\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?landmark skos:hiddenLabel {norm_label_var}.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        GRAPH ?g {{\n",
    "            ?landmark a addr:Landmark; rdfs:label {label_var}.\n",
    "            BIND({norm_label_function} AS {norm_label_var})\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    query2 = prefixes + f\"\"\"\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?landmark skos:exactMatch ?tmpLandmark.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE\n",
    "    {{\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        {{\n",
    "            SELECT DISTINCT ?insee {{\n",
    "                GRAPH ?g {{\n",
    "                    ?tmpLandmark a addr:Landmark; geofla:numInsee ?insee.\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        BIND(URI(CONCAT(STR(URI(ban:)), \"LM_\", STRUUID())) AS ?landmark)\n",
    "\n",
    "        GRAPH ?g {{\n",
    "            ?tmpLandmark a addr:Landmark; addr:isLandmarkType ?landmarkType; geofla:numInsee ?insee.\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Détection des doublons sur les codes postaux\n",
    "\n",
    "    query3 = prefixes + f\"\"\"\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?landmark skos:exactMatch ?tmpLandmark.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE\n",
    "    {{\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        {{\n",
    "            SELECT DISTINCT ?postalCode {{\n",
    "                GRAPH ?g {{\n",
    "                    ?tmpLandmark a addr:Landmark; addr:isLandmarkType ltype:PostalCode; rdfs:label ?postalCode.\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        BIND(URI(CONCAT(STR(URI(ban:)), \"LM_\", STRUUID())) AS ?landmark)\n",
    "\n",
    "        GRAPH ?g {{\n",
    "            ?tmpLandmark a addr:Landmark; addr:isLandmarkType ltype:PostalCode; rdfs:label ?postalCode.\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Détection des doublons sur les voies (même nom et appartient à la même commune ou au même arrondissement)\n",
    "\n",
    "    query4 = prefixes + f\"\"\"\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?landmark skos:exactMatch ?tmpLandmark.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE\n",
    "    {{\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        {{\n",
    "            SELECT DISTINCT ?label ?district WHERE {{\n",
    "                GRAPH ?g {{\n",
    "                    ?tmpLandmark a addr:Landmark; addr:isLandmarkType ltype:Thoroughfare.\n",
    "                    ?addrSeg a addr:AddressSegment; addr:relatum ?tmpLandmark; addr:nextStep [a addr:AddressSegment; addr:relatum ?tmpDistrict].\n",
    "                    ?tmpDistrict a addr:Landmark; addr:isLandmarkType ltype:District.\n",
    "                    ?district skos:exactMatch ?tmpDistrict.\n",
    "                }}\n",
    "                GRAPH ?gTmp {{\n",
    "                    ?tmpLandmark skos:hiddenLabel ?normLabel.\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        BIND(URI(CONCAT(STR(URI(ban:)), \"LM_\", STRUUID())) AS ?landmark)\n",
    "\n",
    "        GRAPH ?g {{\n",
    "            ?tmpLandmark a addr:Landmark; addr:isLandmarkType ltype:Thoroughfare.\n",
    "                    ?addrSeg a addr:AddressSegment; addr:relatum ?tmpLandmark; addr:nextStep [a addr:AddressSegment; addr:relatum ?tmpDistrict].\n",
    "                    ?tmpDistrict a addr:Landmark; addr:isLandmarkType ltype:District.\n",
    "                    ?district skos:exactMatch ?tmpDistrict.\n",
    "        }}\n",
    "        GRAPH ?gTmp {{\n",
    "            ?tmpLandmark skos:hiddenLabel ?normLabel.\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Transfert des données des ressources temporaires vers les permanentes.\n",
    "\n",
    "    query5 = prefixes + f\"\"\"\n",
    "    DELETE {{\n",
    "        GRAPH ?g {{\n",
    "            ?s ?p ?tmpLandmark.\n",
    "            ?tmpLandmark ?p ?o.\n",
    "        }}\n",
    "    }}\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?s ?p ?landmark.\n",
    "            ?landmark ?p ?o.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        ?landmark skos:exactMatch ?tmpLandmark.\n",
    "        GRAPH ?g {{\n",
    "            {{?tmpLandmark ?p ?o}} UNION {{?s ?p ?tmpLandmark}}\n",
    "          }}\n",
    "    }} ; \n",
    "\n",
    "    DELETE {{\n",
    "        ?landmark skos:exactMatch ?tmpLandmark.\n",
    "    }}\n",
    "    WHERE {{\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        GRAPH ?g {{\n",
    "            ?landmark skos:exactMatch ?tmpLandmark.\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    queries = [query1, query2, query3, query4, query5]\n",
    "    for query in queries:\n",
    "        gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'événéments / de changements ainsi que des attributs à tous les repères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_elements_for_landmarks(graphdb_url, project_name, source_graph_uri):\n",
    "    \"\"\"\n",
    "    Ajouter des éléments comme les changements, les événements, les attributs et leurs versions\n",
    "    \"\"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n",
    "    PREFIX geofla: <http://data.ign.fr/def/geofla#>\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#> \n",
    "    PREFIX ban: <http://rdf.geohistoricaldata.org/id/address/sources/ban/>\n",
    "    PREFIX ctype: <http://rdf.geohistoricaldata.org/id/codes/address/changeType/>\n",
    "    PREFIX atype: <http://rdf.geohistoricaldata.org/id/codes/address/attributeType/>\n",
    "    DELETE {{\n",
    "        GRAPH ?g {{ \n",
    "            ?landmark geo:asWKT ?geom; geofla:numInsee ?inseeCode.\n",
    "        }}\n",
    "    }}\n",
    "    INSERT {{\n",
    "        GRAPH ?g {{\n",
    "            ?landmark addr:hasAttribute ?nameAttribute, ?geomAttribute.\n",
    "            ?nameAttribute a addr:Attribute; addr:isAttributeType atype:NameAttribute; addr:version ?versionNameAttribute1, ?versionNameAttribute2.\n",
    "            ?geomAttribute a addr:Attribute; addr:isAttributeType atype:GeometryAttribute; addr:version ?versionGeomAttribute.\n",
    "            ?versionNameAttribute1 a addr:AttributeVersion; addr:versionValue ?label.\n",
    "            ?versionNameAttribute2 a addr:AttributeVersion; addr:versionValue ?inseeCode.\n",
    "            ?versionGeomAttribute a addr:AttributeVersion; addr:versionValue ?geom.\n",
    "        }}  \n",
    "    }}\n",
    "    WHERE {{\n",
    "        BIND({source_graph_uri.n3()} AS ?g)\n",
    "        GRAPH ?g {{\n",
    "            {{\n",
    "                SELECT * {{\n",
    "                    ?landmark a addr:Landmark; rdfs:label ?label.\n",
    "                    OPTIONAL {{?landmark geo:asWKT ?geom}}\n",
    "                    OPTIONAL {{?landmark geofla:numInsee ?inseeCode}}\n",
    "                }}\n",
    "            }}\n",
    "            BIND(URI(CONCAT(STR(URI(ban:)), \"AN_\", STRUUID())) AS ?nameAttribute)\n",
    "            BIND(URI(CONCAT(STR(URI(ban:)), \"ANV_\", STRUUID())) AS ?versionNameAttribute1)\n",
    "            BIND(IF(BOUND(?inseeCode), URI(CONCAT(STR(URI(ban:)), \"ANV_\", STRUUID())), ?x) AS ?versionNameAttribute2)\n",
    "            BIND(IF(BOUND(?geom), URI(CONCAT(STR(URI(ban:)), \"AG_\", STRUUID())), ?x) AS ?geomAttribute)\n",
    "            BIND(IF(BOUND(?geom), URI(CONCAT(STR(URI(ban:)), \"AGV_\", STRUUID())), ?x) AS ?versionGeomAttribute)\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'un processus de création des données de la BAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_factoid_process_ban(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, ban_graph_name, facts_graph_name,\n",
    "                               ban_csv_file, ban_mapping_file, ban_kg_file):\n",
    "    \"\"\"\n",
    "    Fonction pour faire l'ensemble des processus relatifs à la création des factoïdes pour les données de la BAN\n",
    "    \"\"\"\n",
    "\n",
    "    # Récupération des URI des graphes nommés\n",
    "    ban_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, ban_graph_name))\n",
    "    facts_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, facts_graph_name))\n",
    "\n",
    "    # A partir des fichiers csv décrivant les adresses de la BAN dans Paris, convertir en un graphe de connaissance selon le mapping défini\n",
    "    # Puis import du graphe dans le répertoire dont le nom est `project_name` et dans le graphe nommé donné par `graph_name`\n",
    "    from_raw_to_data_to_graphdb(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, ban_graph_name, ban_csv_file, ban_mapping_file, ban_kg_file)\n",
    "\n",
    "    # Nettoyer les données en fusionnant les doublons après l'import dans GraphDB\n",
    "    clean_ban_graph(graphdb_url, project_name, ban_graph_uri)\n",
    "\n",
    "    # Ajout d'éléments manquants\n",
    "    add_missing_elements_for_landmarks(graphdb_url, project_name, ban_graph_uri)\n",
    "\n",
    "    # L'URI ci-dessous définit la source liée à la BAN\n",
    "    ban_source_uri = URIRef(\"http://rdf.geohistoricaldata.org/id/address/facts/Source_BAN\")\n",
    "    create_source_ban(graphdb_url, project_name, ban_source_uri, facts_graph_uri)\n",
    "\n",
    "    # Ajout de labels normalisés\n",
    "    add_normalized_label_for_landmarks(graphdb_url, project_name, ban_graph_uri)\n",
    "    \n",
    "    # Ajout de liens entre les ressources de type repère et la source\n",
    "    add_source_resources_links(graphdb_url, project_name, ban_source_uri, ban_graph_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voies de Paris via Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des données liées à la source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_wikidata(graphdb_url, project_name, source_resource_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    query = f\"\"\"\n",
    "        PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#> \n",
    "        PREFIX facts: <http://rdf.geohistoricaldata.org/id/address/facts/>\n",
    "        PREFIX rico: <https://www.ica.org/standards/RiC/ontology#>\n",
    "\n",
    "        INSERT DATA {{\n",
    "            GRAPH {facts_graph_uri.n3()} {{\n",
    "                {source_resource_uri.n3()} a rico:Record;\n",
    "                    rdfs:label \"Wikidata\"@fr.\n",
    "            }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection des voies de Paris sur Wikidata via une requête de sélection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via une requête SPARQL de sélection, on récupère une liste de ressources à créér :\n",
    "* pour chaque ressource décrivant une voie dans Paris, on créé autant de ressources qu'elle a de nom officiel. La place de la Nation ([wd:Q1573359](https://www.wikidata.org/entity/Q1573359)) a quatre noms officiels donc on aura 4 ressources. Pour celles qui n'ont pas de nom officiel, on créé une seule ressource dont le nom est le label en français\n",
    "* ces ressources créées seront liées à celle de Wikidata dont elle provient via `skos:closeMatch`\n",
    "* chaque ressource créée suit la structure définie par l'ontologie\n",
    "* le résultat de la requête est stocké dans un fichier csv qui sera converti en graphe de connaissance via Ontotext Refine et un fichier de mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paris_thoroughfares_from_wikidata(out_csv_file):\n",
    "    query = f\"\"\"\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#> \n",
    "    PREFIX source: <http://rdf.geohistoricaldata.org/id/address/sources/wikidata/> \n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "    PREFIX pq: <http://www.wikidata.org/prop/qualifier/>\n",
    "    PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
    "    PREFIX p: <http://www.wikidata.org/prop/>\n",
    "    PREFIX pqv: <http://www.wikidata.org/prop/qualifier/value/>\n",
    "    PREFIX wb: <http://wikiba.se/ontology#>\n",
    "    PREFIX time: <http://www.w3.org/2006/time#>\n",
    "\n",
    "    SELECT ?landmarkId ?voie ?nomOff ?dateStartStamp ?dateStartPrec ?dateStartCal ?dateEndStamp ?dateEndPrec ?dateEndCal\n",
    "    WHERE {{\n",
    "\n",
    "        BIND(CONCAT(\"LM_\", STRUUID()) AS ?landmarkId)\n",
    "        {{\n",
    "            SELECT DISTINCT * WHERE {{\n",
    "                {{?voie p:P361 [ps:P361 wd:Q16024163].}}UNION{{?voie p:P361 [ps:P361 wd:Q107311481].}}\n",
    "                {{?voie p:P1448 ?nomOffSt.\n",
    "                    ?nomOffSt ps:P1448 ?nomOff.\n",
    "                    OPTIONAL {{?nomOffSt pq:P580 ?dateStartStamp; pqv:P580 [wb:timePrecision ?dateStartPrecRaw; wb:timeCalendarModel ?dateStartCal]}}\n",
    "                    OPTIONAL {{?nomOffSt pq:P582 ?dateEndStamp; pqv:P582 [wb:timePrecision ?dateEndPrecRaw; wb:timeCalendarModel ?dateEndCal]}}\n",
    "                }}UNION{{\n",
    "                    ?voie rdfs:label ?nomOff.\n",
    "                    FILTER (LANG(?nomOff) = \"fr\")\n",
    "                    MINUS {{?voie p:P1448 ?nomOffSt}}\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        BIND(IF(?dateStartPrecRaw = 11, time:unitDay, \n",
    "                        IF(?dateStartPrecRaw = 10, time:unitMonth,\n",
    "                            IF(?dateStartPrecRaw = 9, time:unitYear,\n",
    "                                IF(?dateStartPrecRaw = 8, time:unitDecade,\n",
    "                                    IF(?dateStartPrecRaw = 7, time:unitCentury,\n",
    "                                        IF(?dateStartPrecRaw = 6, time:unitMillenium, ?x\n",
    "                                    )))))) AS ?dateStartPrec)\n",
    "        BIND(IF(?dateEndPrecRaw = 11, time:unitDay, \n",
    "                        IF(?dateEndPrecRaw = 10, time:unitMonth,\n",
    "                            IF(?dateEndPrecRaw = 9, time:unitYear,\n",
    "                                IF(?dateEndPrecRaw = 8, time:unitDecade,\n",
    "                                    IF(?dateEndPrecRaw = 7, time:unitCentury,\n",
    "                                        IF(?dateEndPrecRaw = 6, time:unitMillenium, ?x\n",
    "                                    )))))) AS ?dateEndPrec)\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    wd.save_select_query_as_csv_file(query, out_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'un processus de création des données de Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_factoid_process_wikidata(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, wdpt_graph_name, facts_graph_name,\n",
    "                               wdpt_csv_file, wdpt_mapping_file, wdpt_kg_file):\n",
    "    \"\"\"\n",
    "    Fonction pour faire l'ensemble des processus relatifs à la création des factoïdes pour les données de Wikidata\n",
    "    \"\"\"\n",
    "\n",
    "    # Récupération des URI des graphes nommés\n",
    "    wdpt_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, wdpt_graph_name))\n",
    "    facts_graph_uri = URIRef(gd.get_graph_uri_from_name(graphdb_url, project_name, facts_graph_name))\n",
    "\n",
    "    # Récupération des données via le endpoint de Wikidatadans un fichier CSV\n",
    "    # get_paris_thoroughfares_from_wikidata(wdpt_csv_file)\n",
    "\n",
    "    # A partir des fichiers csv décrivant les adresses de la BAN dans Paris, convertir en un graphe de connaissance selon le mapping défini\n",
    "    # Puis import du graphe dans le répertoire dont le nom est `project_name` et dans le graphe nommé donné par `graph_name`\n",
    "    from_raw_to_data_to_graphdb(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, wdpt_graph_name, wdpt_csv_file, wdpt_mapping_file, wdpt_kg_file)\n",
    "\n",
    "    # Ajout d'éléments manquants\n",
    "    add_missing_elements_for_landmarks(graphdb_url, project_name, wdpt_graph_uri)\n",
    "\n",
    "    # L'URI ci-dessous définit la source liée à Wikidata\n",
    "    wdpt_source_uri = URIRef(\"http://rdf.geohistoricaldata.org/id/address/facts/Source_WD\")\n",
    "    create_source_wikidata(graphdb_url, project_name, wdpt_source_uri, facts_graph_uri)\n",
    "\n",
    "    # Ajout de labels normalisés\n",
    "    add_normalized_label_for_landmarks(graphdb_url, project_name, wdpt_graph_uri)\n",
    "    \n",
    "    # Ajout de liens entre les ressources de type repère et la source\n",
    "    add_source_resources_links(graphdb_url, project_name, wdpt_source_uri, wdpt_graph_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des faits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de données dans le graphe des faits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de fonctions pour peupler le graphe des faits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unlinked_resources(graphdb_url, project_name, resource_class:str, resource_prefix:str, source_graph_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    # Créer des ressources en tant que fait et créer un lien de provenance\n",
    "    query = f\"\"\"\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#>\n",
    "    PREFIX facts: <http://rdf.geohistoricaldata.org/id/address/facts/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    INSERT {{\n",
    "        GRAPH {source_graph_uri.n3()} {{\n",
    "            ?resource owl:sameAs ?sourceResource.\n",
    "        }}\n",
    "        GRAPH {facts_graph_uri.n3()} {{\n",
    "            ?resource a ?type.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        ?type rdfs:subClassOf* addr:{resource_class}.\n",
    "        GRAPH {source_graph_uri.n3()} {{\n",
    "            ?sourceResource a ?type.\n",
    "        }}\n",
    "        MINUS {{?sourceResource owl:sameAs [a addr:{resource_class}]}}\n",
    "        BIND(URI(CONCAT(STR(URI(facts:)), \"{resource_prefix}_\", STRUUID())) AS ?resource)\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    gd.update_query(query, graphdb_url, project_name)\n",
    "\n",
    "def create_linked_between_similar_thoroughfares(graphdb_url, project_name, source_graph_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    \"\"\"\n",
    "    Pour les repères de type VOIE définis dans le graphe nommé `source_graph_uri`, les lier avec un repère de même type défini dans `facts_graph_uri` s'ils ont un nom similaire.\n",
    "    Le lien créé est mis dans `source_facts_graph_uri`.\n",
    "    \"\"\"\n",
    "    prefixes = \"\"\"\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#>\n",
    "    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX ltype: <http://rdf.geohistoricaldata.org/id/codes/address/landmarkType/>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    \"\"\"\n",
    "\n",
    "    query = prefixes + f\"\"\"\n",
    "    INSERT {{\n",
    "        GRAPH {source_graph_uri.n3()} {{\n",
    "            ?factsLandmark owl:sameAs ?sourceLandmark.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        GRAPH {source_graph_uri.n3()} {{\n",
    "            ?sourceLandmark a addr:Landmark; addr:isLandmarkType ltype:Thoroughfare.\n",
    "        }}\n",
    "        GRAPH {facts_graph_uri.n3()} {{\n",
    "            ?factsLandmark a addr:Landmark.\n",
    "           }}\n",
    "        MINUS {{?factsLandmark owl:sameAs ?sourceLandmark}}\n",
    "        ?sourceLandmark skos:hiddenLabel ?label.\n",
    "        ?factsLandmark skos:hiddenLabel ?label.\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    gd.update_query(query, graphdb_url, project_name)\n",
    "\n",
    "def select_transfer_implicit_triples(graphdb_url, project_name, tmp_folder, source_graph_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#>\n",
    "    PREFIX facts: <http://rdf.geohistoricaldata.org/id/address/facts/>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX rico: <https://www.ica.org/standards/RiC/ontology#>\n",
    "    \n",
    "    SELECT ?s ?p ?o FROM <http://www.ontotext.com/implicit>\n",
    "        WHERE {{\n",
    "            ?s ?p ?o.\n",
    "            FILTER(?p in (addr:hasAttribute,addr:isAttributeType,addr:appliedTo,addr:dependsOn,addr:hasTime,addr:isChangeType,addr:isLandmarkType,addr:makesEffective,addr:outdates,addr:relatum,addr:timeCalendar,addr:timePrecision,addr:timeStamp,addr:versionValue,addr:version,rdfs:label,skos:hiddenLabel,rico:isOrWasDescribedBy))\n",
    "            MINUS {{\n",
    "                GRAPH {source_graph_uri.n3()} {{\n",
    "                    ?s a ?typeS.\n",
    "                }}\n",
    "            }}\n",
    "            MINUS {{\n",
    "                GRAPH {source_graph_uri.n3()} {{\n",
    "                    ?o a ?typeO.\n",
    "                }}\n",
    "            }}\n",
    "            }}\n",
    "    \"\"\"\n",
    "\n",
    "    res_query_file_name = \"transfer_implicit_triples.csv\"\n",
    "    res_query_file = os.path.join(tmp_folder, res_query_file_name)\n",
    "\n",
    "    gd.select_query_to_txt_file(query, graphdb_url, project_name, res_query_file)\n",
    "\n",
    "def transfer_implicit_triples(graphdb_url, project_name, source_graph_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX addr: <http://rdf.geohistoricaldata.org/def/address#>\n",
    "    PREFIX facts: <http://rdf.geohistoricaldata.org/id/address/facts/>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX rico: <https://www.ica.org/standards/RiC/ontology#>\n",
    "    \n",
    "    INSERT {{\n",
    "        GRAPH {facts_graph_uri.n3()} {{\n",
    "            ?s ?p ?o.\n",
    "        }}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        GRAPH {facts_graph_uri.n3()} {{\n",
    "                ?s a ?typeS.\n",
    "        }}\n",
    "        MINUS {{\n",
    "            GRAPH {source_graph_uri.n3()} {{\n",
    "                ?o a ?typeO.\n",
    "            }} \n",
    "        }}\n",
    "        ?s ?p ?o.\n",
    "\n",
    "        MINUS {{\n",
    "            GRAPH ?g {{\n",
    "                ?s ?p ?o.\n",
    "            }}\n",
    "        }}\n",
    "        FILTER(?p in (addr:hasAttribute,addr:isAttributeType,addr:appliedTo,addr:dependsOn,addr:hasTime,addr:isChangeType,addr:isLandmarkType,addr:makesEffective,addr:outdates,addr:relatum,addr:timeCalendar,addr:timePrecision,addr:timeStamp,addr:versionValue,addr:version,rdfs:label,skos:hiddenLabel,rico:isOrWasDescribedBy))\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    gd.update_query(query, graphdb_url, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de voies à partir des différentes sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La création de voies se fait de la manière suivante :\n",
    "* on normalise les labels des repères, qui sont stockés dans un graphe nommé temporaire\n",
    "* on sélectionne une source\n",
    "* pour chaque ressource définie dans la source, on regarde si elle existe dans le graphe des faits (via des critères pré-définis comme le nom)\n",
    "    * si la ressource existe, on crée un lien `?a addr:isReferencedBy ?b` décrivant le fait que la ressource existe\n",
    "    * sinon, on la crée et on ajoute un lien `?a addr:isCreatedBy ?b`\n",
    "* on refait le processus suivant pour une autre source jusqu'à les avoir toutes faites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_factoids_in_facts(graphdb_url, project_name, source_graph_uri:URIRef, facts_graph_uri:URIRef):\n",
    "    create_linked_between_similar_thoroughfares(graphdb_url, project_name, source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"Landmark\", \"LM\", source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"Address\", \"ADDR\", source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"LandmarkRelation\", \"LR\", source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"Attribute\", \"ATTR\", source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"AttributeVersion\", \"AV\", source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"Change\", \"CG\", source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"Event\", \"EV\", source_graph_uri, facts_graph_uri)\n",
    "    create_unlinked_resources(graphdb_url, project_name, \"TemporalEntity\", \"TE\", source_graph_uri, facts_graph_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processus final et itératif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des données de la ville de Paris\n",
    "# create_factoid_process_ville_paris(graphdb_url, project_name, ontorefine_url, ontorefine_cmd, vpt_graph_name, facts_graph_name,\n",
    "#                                    vpta_csv_file, vptc_csv_file, vpta_mapping_file, vptc_mapping_file, vpta_kg_file, vptc_kg_file)\n",
    "# insert_factoids_in_facts(graphdb_url, project_name, vpt_graph_uri, facts_graph_uri)\n",
    "# transfer_implicit_triples(graphdb_url, project_name, vpt_graph_uri, facts_graph_uri)\n",
    "# gd.remove_graph(graphdb_url, project_name, vpt_graph_name)\n",
    "\n",
    "# # Import des données de la BAN\n",
    "# create_factoid_process_ban(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, bpa_graph_name, facts_graph_name, bpa_csv_file, bpa_mapping_file, bpa_kg_file)\n",
    "# insert_factoids_in_facts(graphdb_url, project_name, bpa_graph_uri, facts_graph_uri)\n",
    "# transfer_implicit_triples(graphdb_url, project_name, bpa_graph_uri, facts_graph_uri)\n",
    "# gd.remove_graph(graphdb_url, project_name, bpa_graph_name)\n",
    "\n",
    "# # Import des données de Wikidata\n",
    "# create_factoid_process_wikidata(graphdb_url, ontorefine_url, ontorefine_cmd, project_name, wdpt_graph_name, facts_graph_name, wdpt_csv_file, wdpt_mapping_file, wdpt_kg_file)\n",
    "# insert_factoids_in_facts(graphdb_url, project_name, wdpt_graph_uri, facts_graph_uri)\n",
    "# transfer_implicit_triples(graphdb_url, project_name, wdpt_graph_uri, facts_graph_uri)\n",
    "# gd.remove_graph(graphdb_url, project_name, wdpt_graph_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
